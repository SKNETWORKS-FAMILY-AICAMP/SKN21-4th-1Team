# ëª¨ë“ˆí™”ëœ ë²•ë¥  RAG ì±—ë´‡ ì½”ë“œ ë¶„ì„

**ì‘ì„±ì¼**: 2026-01-29  
**ëŒ€ìƒ ë””ë ‰í† ë¦¬**: `chat/ai_module/`  
**ëª©ì **: ë¦¬íŒ©í† ë§ëœ ëª¨ë“ˆ êµ¬ì¡° ë¶„ì„ ë° ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆ ì œì‹œ

---
## ğŸ“‹ ëª©ì°¨

1. [ëª¨ë“ˆ êµ¬ì¡° ê°œìš”](#1-ëª¨ë“ˆ-êµ¬ì¡°-ê°œìš”)
2. [íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„](#2-íŒŒì¼ë³„-ìƒì„¸-ë¶„ì„)
   - 2.1 [`__init__.py`](#21-__init__py)
   - 2.2 [`config.py`](#22-configpy)
   - 2.3 [`prompts.py`](#23-promptspy)
   - 2.4 [`schemas.py`](#24-schemaspy)
   - 2.5 [`infrastructure.py`](#25-infrastructurepy)
   - 2.6 [`graph.py`](#26-graphpy)
3. [íŒŒì¼ ê°„ ê´€ê³„ë„](#3-íŒŒì¼-ê°„-ê´€ê³„ë„)
4. [ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆ](#4-ì„±ëŠ¥-ìµœì í™”-ë°©ì•ˆ)
5. [ìµœì í™” ì½”ë“œ ìˆ˜ì • ê°€ì´ë“œ](#5-ìµœì í™”-ì½”ë“œ-ìˆ˜ì •-ê°€ì´ë“œ)

---
## 1. ëª¨ë“ˆ êµ¬ì¡° ê°œìš”

ê¸°ì¡´ì˜ ë‹¨ì¼ íŒŒì¼(`chatbot_graph_V8_FINAL.py`, 965ì¤„)ì„ **6ê°œì˜ ëª¨ë“ˆ**ë¡œ ë¶„ë¦¬í•˜ì—¬ ìœ ì§€ë³´ìˆ˜ì„±ê³¼ í™•ì¥ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

### íŒŒì¼ êµ¬ì¡°

```
chat/ai_module/
â”œâ”€â”€ __init__.py          (6ì¤„)   - íŒ¨í‚¤ì§€ ì§„ì…ì 
â”œâ”€â”€ config.py            (38ì¤„)  - ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ prompts.py           (98ì¤„)  - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ schemas.py           (56ì¤„)  - ë°ì´í„° ìŠ¤í‚¤ë§ˆ
â”œâ”€â”€ infrastructure.py    (207ì¤„) - ì¸í”„ë¼ ì»´í¬ë„ŒíŠ¸
â””â”€â”€ graph.py             (500ì¤„) - LangGraph ë¡œì§
```

### ì„¤ê³„ ì›ì¹™

| ì›ì¹™ | ì„¤ëª… |
|------|------|
| **ë‹¨ì¼ ì±…ì„** | ê° íŒŒì¼ì´ í•˜ë‚˜ì˜ ëª…í™•í•œ ì—­í• ë§Œ ìˆ˜í–‰ |
| **ì˜ì¡´ì„± ë¶„ë¦¬** | ì„¤ì • â†’ ìŠ¤í‚¤ë§ˆ â†’ ì¸í”„ë¼ â†’ ë¡œì§ ìˆœìœ¼ë¡œ ì˜ì¡´ |
| **ì¬ì‚¬ìš©ì„±** | í”„ë¡¬í”„íŠ¸, ì„¤ì • ë“±ì„ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜ì • ê°€ëŠ¥ |
| **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±** | ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ |

---
## 2. íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„

### 2.1 `__init__.py`

**ì—­í• **: íŒ¨í‚¤ì§€ì˜ **ê³µê°œ API** ì •ì˜

```python
from .config import Config
from .infrastructure import VectorStoreManager, JinaReranker
from .graph import LegalRAGBuilder

__all__ = ["Config", "VectorStoreManager", "JinaReranker", "LegalRAGBuilder"]
```

#### í•µì‹¬ ê¸°ëŠ¥

- **ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤**: ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ `from chat.ai_module import Config` í˜•íƒœë¡œ ì„í¬íŠ¸ ê°€ëŠ¥
- **ìº¡ìŠí™”**: ë‚´ë¶€ êµ¬í˜„(`prompts`, `schemas`)ì€ ìˆ¨ê¸°ê³  í•„ìš”í•œ ê²ƒë§Œ ë…¸ì¶œ

#### ì‚¬ìš© ì˜ˆì‹œ

```python
# services.pyì—ì„œ ì‚¬ìš©
from chat.ai_module import Config, LegalRAGBuilder, VectorStoreManager, JinaReranker

config = Config()
builder = LegalRAGBuilder(config)
```

---
### 2.2 `config.py`

**ì—­í• **: **ì¤‘ì•™ ì§‘ì¤‘ì‹ ì„¤ì • ê´€ë¦¬** (Django settings ì—°ë™)

```python
@dataclass
class Config:
    # Django settingsì—ì„œ ê°’ì„ ê°€ì ¸ì˜¤ë˜, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    LLM_MODEL: str = getattr(settings, "LLM_MODEL", "gpt-4o-mini")
    LLM_TEMPERATURE: float = getattr(settings, "LLM_TEMPERATURE", 0.0)
    
    TOP_K_VECTOR: int = getattr(settings, "TOP_K_VECTOR", 10)
    TOP_K_RERANK: int = getattr(settings, "TOP_K_RERANK", 5)
    TOP_K_FINAL: int = getattr(settings, "TOP_K_FINAL", 3)
    
    QDRANT_COLLECTION_NAME: str = getattr(settings, "QDRANT_COLLECTION_NAME", 
                                          os.getenv("QDRANT_COLLECTION_NAME"))
```

#### í•µì‹¬ íŠ¹ì§•

1. **Django í†µí•©**: `django.conf.settings`ì—ì„œ ê°’ì„ ìš°ì„  ê°€ì ¸ì˜´
2. **í™˜ê²½ ë³€ìˆ˜ í´ë°±**: Django settingsì— ì—†ìœ¼ë©´ `.env`ì—ì„œ ê°€ì ¸ì˜´
3. **íƒ€ì… ì•ˆì •ì„±**: `@dataclass`ë¡œ íƒ€ì… íŒíŠ¸ ì œê³µ

#### ì„¤ì • í•­ëª© ë¶„ë¥˜

| ì¹´í…Œê³ ë¦¬ | ì„¤ì • í•­ëª© | ê¸°ë³¸ê°’ |
|----------|-----------|--------|
| **ëª¨ë¸** | `LLM_MODEL` | `gpt-4o-mini` |
| | `EMBEDDING_MODEL` | `Qwen/Qwen3-Embedding-0.6B` |
| | `RERANKER_MODEL` | `jinaai/jina-reranker-v2-base-multilingual` |
| **RAG** | `TOP_K_VECTOR` | 10 |
| | `TOP_K_RERANK` | 5 |
| | `TOP_K_FINAL` | 3 |
| | `RELEVANCE_THRESHOLD` | 0.2 |
| **Qdrant** | `QDRANT_TIMEOUT` | 10ì´ˆ |
| | `QDRANT_PREFER_GRPC` | True |

#### ì„±ëŠ¥ ê´€ë ¨ ì„¤ì •

- **`TOP_K_VECTOR`**: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (â†“ ê°’ â†’ â†‘ ì†ë„, â†“ ì¬í˜„ìœ¨)
- **`QDRANT_TIMEOUT`**: Qdrant ì—°ê²° íƒ€ì„ì•„ì›ƒ (â†“ ê°’ â†’ â†‘ ì‘ë‹µì„±)
- **`QDRANT_PREFER_GRPC`**: gRPC ì‚¬ìš© ì—¬ë¶€ (True â†’ ë” ë¹ ë¦„)

---
### 2.3 `prompts.py`

**ì—­í• **: **ëª¨ë“  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬**

#### í”„ë¡¬í”„íŠ¸ ëª©ë¡

| ë³€ìˆ˜ëª… | ì‚¬ìš© ë…¸ë“œ | ëª©ì  |
|--------|-----------|------|
| `PROMPT_QUERY_EXPANSION` | Query Expander | HyDE + Hybrid ì¿¼ë¦¬ ìƒì„± |
| `PROMPT_ANALYZE` | Analyze | ì§ˆë¬¸ ë¶„ì„ (ì¹´í…Œê³ ë¦¬, ë‚œì´ë„ ë“±) |
| `PROMPT_GENERATE` | Generate | ë‹µë³€ ìƒì„± (ì¸ìš© ê°•ì œ) |
| `PROMPT_EVALUATE` | Evaluate | ë‹µë³€ í’ˆì§ˆ í‰ê°€ |
| `TEMPLATE_CLARIFY` | Clarify | ëª…í™•í™” ìš”ì²­ ë©”ì‹œì§€ |
| `TEMPLATE_NO_RESULTS` | Generate | ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ |

#### ì˜ˆì‹œ: `PROMPT_GENERATE`

```python
PROMPT_GENERATE = """ë‹¹ì‹ ì€ ì—„ê²©í•œ ê¸°ì¤€ì„ ê°€ì§„ ë²•ë¥  AI 'A-TEAM'ì…ë‹ˆë‹¤.

## í•µì‹¬ ì›ì¹™
1. **ì¦ê±° ê¸°ë°˜**: ë°˜ë“œì‹œ ì œê³µëœ [ê²€ìƒ‰ëœ ë¬¸ì„œ]ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©
2. **Hallucination ê¸ˆì§€**: ë¬¸ì„œì— ì—†ëŠ” ë²•ì¡°ë¬¸ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
3. **ì—„ê²©í•œ ì¸ìš©**: ëª¨ë“  ì§„ìˆ  ë’¤ì— [1], [2] ì¶œì²˜ í‘œê¸°

## ë‹µë³€ í˜•ì‹
**ğŸ¤” ë¶„ì„**
...
"""
```

#### ì¥ì 

- **ë²„ì „ ê´€ë¦¬**: í”„ë¡¬í”„íŠ¸ ë³€ê²½ ì´ë ¥ ì¶”ì  ìš©ì´
- **A/B í…ŒìŠ¤íŠ¸**: ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ë²„ì „ ë¹„êµ ê°€ëŠ¥
- **ì¬ì‚¬ìš©**: ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œë„ í™œìš© ê°€ëŠ¥

---
### 2.4 `schemas.py`

## 1) `AgentState` (TypedDict) - LangGraph ìƒíƒœ ì»¨í…Œì´ë„ˆ

### ì „ì²´ ì½”ë“œ

```python
class AgentState(TypedDict):
    """LangGraph Agentì˜ ìƒíƒœ"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    user_query: str
    query_analysis: Optional[dict]
    retrieved_docs: Optional[List[Any]]
    generated_answer: Optional[str]
    next_action: Optional[str]
    evaluation_result: Optional[dict]
    retry_count: Optional[int]
```

### í•„ë“œë³„ ìƒì„¸ ì„¤ëª…

| í•„ë“œ                | íƒ€ì…                    | ì„¤ëª…                                                   | ì˜ˆì‹œ ê°’                                                            |
| ------------------- | ----------------------- | ------------------------------------------------------ | ------------------------------------------------------------------ |
| `messages`          | `Sequence[BaseMessage]` | LangChain ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ (ëŒ€í™” ë§¥ë½ ìœ ì§€)             | `[HumanMessage("í‡´ì§ê¸ˆ ì–¸ì œ ë°›ë‚˜ìš”?"), AIMessage("14ì¼ ì´ë‚´...")]` |
| `user_query`        | `str`                   | ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸                                     | `"í‡´ì§ê¸ˆ ì–¸ì œ ë°›ë‚˜ìš”?"`                                            |
| `query_analysis`    | `Optional[dict]`        | Analyze ë…¸ë“œì˜ ë¶„ì„ ê²°ê³¼ (QueryAnalysisë¥¼ dictë¡œ ë³€í™˜) | `{"category": "ë…¸ë™ë²•", "complexity": "simple"}`                   |
| `retrieved_docs`    | `Optional[List[Any]]`   | Search ë…¸ë“œì—ì„œ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸                     | `[Document(page_content="ê·¼ë¡œê¸°ì¤€ë²• ì œ36ì¡°...")]`                  |
| `generated_answer`  | `Optional[str]`         | Generate ë…¸ë“œì—ì„œ ìƒì„±ëœ ìµœì¢… ë‹µë³€                     | `"í‡´ì§ê¸ˆì€ í‡´ì§ í›„ 14ì¼ ì´ë‚´ì— ì§€ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤[1]."`               |
| `next_action`       | `Optional[str]`         | ë‹¤ìŒ ì‹¤í–‰í•  ì•¡ì…˜ (ë¼ìš°íŒ…ìš©)                            | `"search"`, `"clarify"`, `"end"`                                   |
| `evaluation_result` | `Optional[dict]`        | Evaluate ë…¸ë“œì˜ í‰ê°€ ê²°ê³¼                              | `{"quality_score": 5, "needs_more_search": false}`                 |
| `retry_count`       | `Optional[int]`         | ì¬ê²€ìƒ‰ ì‹œë„ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)                      | `0`, `1`, `2`                                                      |

### í•µì‹¬ íŠ¹ì§•

**`Annotated[Sequence[BaseMessage], add_messages]`**: LangGraphì˜ íŠ¹ìˆ˜ ê¸°ëŠ¥
- `add_messages`ëŠ” ë©”ì‹œì§€ë¥¼ **ëˆ„ì **ì‹œí‚¤ëŠ” ë¦¬ë“€ì„œ í•¨ìˆ˜
- ê° ë…¸ë“œê°€ ìƒˆ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ë©´ ìë™ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ì— ë³‘í•©ë¨

### ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ

```python
# Analyze ë…¸ë“œì—ì„œ ìƒíƒœ ì—…ë°ì´íŠ¸
def analyze_query(state: AgentState) -> dict:
    analysis = {"category": "ë…¸ë™ë²•", "complexity": "simple"}
    return {"query_analysis": analysis}  # ê¸°ì¡´ stateì— ë³‘í•©ë¨

# Search ë…¸ë“œì—ì„œ ìƒíƒœ ì½ê¸°
def search_documents(state: AgentState) -> dict:
    query = state["user_query"]  # "í‡´ì§ê¸ˆ ì–¸ì œ ë°›ë‚˜ìš”?"
    analysis = state["query_analysis"]  # {"category": "ë…¸ë™ë²•", ...}
    # ê²€ìƒ‰ ë¡œì§...
    return {"retrieved_docs": docs}
```

---

## 2) `HybridQuery` (Pydantic) - ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼

### ì „ì²´ ì½”ë“œ

```python
class HybridQuery(BaseModel):
    """HyDE + Hybrid Searchë¥¼ ìœ„í•œ ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼"""
    keyword_query: str = Field(
        description="BM25 ê²€ìƒ‰ìš©: ì¡°ì‚¬ ì œê±°ëœ í•µì‹¬ ë²•ë¥  í‚¤ì›Œë“œ")
    semantic_query: str = Field(
        description="Vector ê²€ìƒ‰ìš©: ì§ˆë¬¸ ì˜ë„ì™€ ë¬¸ë§¥ì„ í¬í•¨í•œ ìì—°ì–´ ë¬¸ì¥")
    hyde_passage: str = Field(
        description="Vector ê²€ìƒ‰ìš© ê°€ìƒ ë¬¸ì„œ: ì˜ˆìƒë˜ëŠ” ë²•ì¡°ë¬¸ ë‚´ìš© (2-3ë¬¸ì¥)")
```

### í•„ë“œë³„ ì—­í• 

| í•„ë“œ             | ê²€ìƒ‰ ë°©ì‹          | ëª©ì                                       | ì˜ˆì‹œ                                                                           |
| ---------------- | ------------------ | ----------------------------------------- | ------------------------------------------------------------------------------ |
| `keyword_query`  | **Sparse (BM25)**  | ë²•ë¥  ìš©ì–´ì˜ ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­            | `"ê·¼ë¡œê¸°ì¤€ë²• í‡´ì§ê¸ˆ ì§€ê¸‰ ì²­êµ¬"`                                                |
| `semantic_query` | **Dense (Vector)** | ì§ˆë¬¸ì˜ ì˜ë¯¸ì™€ ì˜ë„ íŒŒì•…                   | `"í‡´ì§ê¸ˆ ì§€ê¸‰ ê¸°í•œê³¼ ì²­êµ¬ ë°©ë²•ì— ëŒ€í•œ ê·¼ë¡œê¸°ì¤€ë²• ê·œì •"`                        |
| `hyde_passage`   | **Dense (Vector)** | HyDE ê¸°ë²•: ì˜ˆìƒ ë‹µë³€ìœ¼ë¡œ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ | `"ê·¼ë¡œê¸°ì¤€ë²• ì œ36ì¡°ì— ë”°ë¥´ë©´ í‡´ì§ê¸ˆì€ í‡´ì§ í›„ 14ì¼ ì´ë‚´ì— ì§€ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤..."` |

### ì‹¤ì œ LLM ì¶œë ¥ ì˜ˆì‹œ

**ì…ë ¥ ì§ˆë¬¸**: `"í‡´ì§ê¸ˆ ëª» ë°›ì•˜ì–´ìš”"`

**LLMì´ ìƒì„±í•œ JSON**:
```json
{
  "keyword_query": "ê·¼ë¡œê¸°ì¤€ë²• í‡´ì§ê¸ˆ ì§€ê¸‰ ì²­êµ¬",
  "semantic_query": "í‡´ì§ê¸ˆì„ ë°›ì§€ ëª»í•œ ê²½ìš° ë²•ì  ê¶Œë¦¬ì™€ ì²­êµ¬ ë°©ë²•",
  "hyde_passage": "ê·¼ë¡œê¸°ì¤€ë²• ì œ36ì¡°ì— ë”°ë¥´ë©´ í‡´ì§ê¸ˆì€ í‡´ì§ í›„ 14ì¼ ì´ë‚´ì— ì§€ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤. ì§€ê¸‰í•˜ì§€ ì•Šì„ ê²½ìš° ë…¸ë™ì²­ì— ì§„ì •ì„ ì œê¸°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
}
```

**Pydanticì´ ìë™ìœ¼ë¡œ íŒŒì‹±**:
```python
hybrid = HybridQuery(
    keyword_query="ê·¼ë¡œê¸°ì¤€ë²• í‡´ì§ê¸ˆ ì§€ê¸‰ ì²­êµ¬",
    semantic_query="í‡´ì§ê¸ˆì„ ë°›ì§€ ëª»í•œ ê²½ìš° ë²•ì  ê¶Œë¦¬ì™€ ì²­êµ¬ ë°©ë²•",
    hyde_passage="ê·¼ë¡œê¸°ì¤€ë²• ì œ36ì¡°ì— ë”°ë¥´ë©´..."
)

# ë°”ë¡œ ì†ì„±ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥
print(hybrid.keyword_query)  # "ê·¼ë¡œê¸°ì¤€ë²• í‡´ì§ê¸ˆ ì§€ê¸‰ ì²­êµ¬"
```

### ì™œ 3ê°œë¡œ ë‚˜ëˆ„ëŠ”ê°€?

- **Sparse (keyword_query)**: "ê·¼ë¡œê¸°ì¤€ë²•", "ì œ36ì¡°" ê°™ì€ ì •í™•í•œ ë²•ë ¹ëª… ë§¤ì¹­
- **Dense (semantic_query + hyde_passage)**: "í‡´ì§ê¸ˆì„ ë°›ì§€ ëª»í•¨" â†’ "í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰" ê°™ì€ ì˜ë¯¸ì  ìœ ì‚¬ì„±
- **Hybrid**: ë‘ ë°©ì‹ì„ ê²°í•©í•˜ì—¬ ì¬í˜„ìœ¨(Recall)ê³¼ ì •ë°€ë„(Precision) ëª¨ë‘ í–¥ìƒ

---

## 3) `QueryAnalysis` (Pydantic) - ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼

### ì „ì²´ ì½”ë“œ

```python
class QueryAnalysis(BaseModel):
    """ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼"""
    category: str = Field(description="ë²•ë¥  ë¶„ì•¼: ë…¸ë™ë²•, í˜•ì‚¬ë²•, ë¯¼ì‚¬ë²•, ê¸°íƒ€")
    intent_type: str = Field(description="ì§ˆë¬¸ ì˜ë„: ë²•ë ¹ì¡°íšŒ, ì ˆì°¨ë¬¸ì˜, ìƒí™©íŒë‹¨, ê¶Œë¦¬í™•ì¸, ë¶„ìŸí•´ê²°, ì¼ë°˜ìƒë‹´")
    needs_clarification: bool = Field(default=False, description="ì§ˆë¬¸ ëª¨í˜¸ ì—¬ë¶€")
    needs_case_law: bool = Field(default=False, description="íŒë¡€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€")
    query_complexity: str = Field(default="medium", description="ì§ˆë¬¸ ë‚œì´ë„: simple, medium, complex")
    clarification_question: str = Field(default="", description="ëª…í™•í™” ì§ˆë¬¸")
    user_situation: str = Field(default="", description="ì‚¬ìš©ì ìƒí™© ìš”ì•½")
    core_question: str = Field(default="", description="í•µì‹¬ ì§ˆë¬¸")
    related_laws: List[str] = Field(default_factory=list, description="ê´€ë ¨ ë²•ë¥ ëª…")
```

### í•„ë“œë³„ ìƒì„¸ ì„¤ëª…

| í•„ë“œ                     | íƒ€ì…        | ìš©ë„                                           | ì˜ˆì‹œ ê°’                                     |
| ------------------------ | ----------- | ---------------------------------------------- | ------------------------------------------- |
| `category`               | `str`       | ë²•ë¥  ë¶„ì•¼ ë¶„ë¥˜ (ê²€ìƒ‰ í•„í„°ë§)                   | `"ë…¸ë™ë²•"`, `"í˜•ì‚¬ë²•"`, `"ë¯¼ì‚¬ë²•"`          |
| `intent_type`            | `str`       | ì§ˆë¬¸ ì˜ë„ íŒŒì•… (ë‹µë³€ ìŠ¤íƒ€ì¼ ê²°ì •)              | `"ë²•ë ¹ì¡°íšŒ"`, `"ì ˆì°¨ë¬¸ì˜"`, `"ìƒí™©íŒë‹¨"`    |
| `needs_clarification`    | `bool`      | **ë¼ìš°íŒ… ê²°ì •**: trueë©´ Clarify ë…¸ë“œë¡œ         | `true` ("í‡´ì§ê¸ˆ"ë§Œ ì…ë ¥ ì‹œ)                 |
| `needs_case_law`         | `bool`      | íŒë¡€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ (í˜„ì¬ ë¯¸ì§€ì›, í–¥í›„ í™•ì¥ìš©) | `true` ("ë¶€ë‹¹í•´ê³  íŒë¡€" ì§ˆë¬¸ ì‹œ)            |
| `query_complexity`       | `str`       | **ì„±ëŠ¥ ìµœì í™”**: simpleì´ë©´ Evaluate ìƒëµ      | `"simple"`, `"medium"`, `"complex"`         |
| `clarification_question` | `str`       | ëª…í™•í™” í•„ìš” ì‹œ ì‚¬ìš©ìì—ê²Œ ë³´ë‚¼ ì§ˆë¬¸            | `"ì–´ë–¤ ìƒí™©ì—ì„œ í‡´ì§ê¸ˆì„ ë°›ì§€ ëª»í•˜ì…¨ë‚˜ìš”?"` |
| `user_situation`         | `str`       | ì‚¬ìš©ì ìƒí™© ìš”ì•½ (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)               | `"íšŒì‚¬ í‡´ì‚¬ í›„ í‡´ì§ê¸ˆ ë¯¸ì§€ê¸‰"`              |
| `core_question`          | `str`       | í•µì‹¬ ì§ˆë¬¸ ì¶”ì¶œ (ê¸´ ì§ˆë¬¸ ìš”ì•½)                  | `"í‡´ì§ê¸ˆ ì§€ê¸‰ ê¸°í•œ"`                        |
| `related_laws`           | `List[str]` | **ê²€ìƒ‰ ë¶€ìŠ¤íŒ…**: ê´€ë ¨ ë²•ë¥ ëª…ìœ¼ë¡œ ì ìˆ˜ ê°€ì¤‘ì¹˜   | `["ê·¼ë¡œê¸°ì¤€ë²•", "ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²•"]`    |

### ì‹¤ì œ LLM ì¶œë ¥ ì˜ˆì‹œ

#### ì˜ˆì‹œ 1: Simple ì§ˆë¬¸

**ì…ë ¥ ì§ˆë¬¸**: `"ê·¼ë¡œê¸°ì¤€ë²• ì œ1ì¡°ê°€ ë­ì•¼?"`

```json
{
  "category": "ë…¸ë™ë²•",
  "intent_type": "ë²•ë ¹ì¡°íšŒ",
  "needs_clarification": false,
  "needs_case_law": false,
  "query_complexity": "simple",
  "clarification_question": "",
  "user_situation": "ê·¼ë¡œê¸°ì¤€ë²• ì œ1ì¡° ë‚´ìš© í™•ì¸",
  "core_question": "ê·¼ë¡œê¸°ì¤€ë²• ì œ1ì¡° ë‚´ìš©",
  "related_laws": ["ê·¼ë¡œê¸°ì¤€ë²•"]
}
```

â†’ **ë¼ìš°íŒ…**: `complexity == "simple"` â†’ Evaluate ë…¸ë“œ ìƒëµ

#### ì˜ˆì‹œ 2: ëª…í™•í™” í•„ìš”

**ì…ë ¥ ì§ˆë¬¸**: `"í‡´ì§ê¸ˆ"`

```json
{
  "category": "ë…¸ë™ë²•",
  "intent_type": "ì¼ë°˜ìƒë‹´",
  "needs_clarification": true,
  "needs_case_law": false,
  "query_complexity": "medium",
  "clarification_question": "í‡´ì§ê¸ˆì— ëŒ€í•´ ì–´ë–¤ ê²ƒì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? (ì§€ê¸‰ ê¸°í•œ, ê³„ì‚° ë°©ë²•, ì²­êµ¬ ì ˆì°¨ ë“±)",
  "user_situation": "í‡´ì§ê¸ˆ ê´€ë ¨ ë¬¸ì˜",
  "core_question": "í‡´ì§ê¸ˆ",
  "related_laws": ["ê·¼ë¡œê¸°ì¤€ë²•", "ê·¼ë¡œìí‡´ì§ê¸‰ì—¬ë³´ì¥ë²•"]
}
```

â†’ **ë¼ìš°íŒ…**: `needs_clarification == true` â†’ Clarify ë…¸ë“œë¡œ ì´ë™

#### ì˜ˆì‹œ 3: Complex ì§ˆë¬¸

**ì…ë ¥ ì§ˆë¬¸**: `"íšŒì‚¬ê°€ ë¶€ë‹¹í•˜ê²Œ í•´ê³ í–ˆëŠ”ë° ë³µì§ ê°€ëŠ¥í•œê°€ìš”? íŒë¡€ë„ ì•Œë ¤ì£¼ì„¸ìš”"`

```json
{
  "category": "ë…¸ë™ë²•",
  "intent_type": "ë¶„ìŸí•´ê²°",
  "needs_clarification": false,
  "needs_case_law": true,
  "query_complexity": "complex",
  "clarification_question": "",
  "user_situation": "ë¶€ë‹¹í•´ê³  í›„ ë³µì§ ê°€ëŠ¥ì„± ë¬¸ì˜",
  "core_question": "ë¶€ë‹¹í•´ê³  ë³µì§ ê°€ëŠ¥ì„± ë° íŒë¡€",
  "related_laws": ["ê·¼ë¡œê¸°ì¤€ë²•", "ë…¸ë™ìœ„ì›íšŒë²•"]
}
```

â†’ **ë¼ìš°íŒ…**: `complexity == "complex"` â†’ Evaluate ë…¸ë“œ ì‹¤í–‰

---

## 4) `AnswerEvaluation` (Pydantic) - ë‹µë³€ í’ˆì§ˆ í‰ê°€

### ì „ì²´ ì½”ë“œ

```python
class AnswerEvaluation(BaseModel):
    """ë‹µë³€ í‰ê°€ ê²°ê³¼"""
    has_legal_basis: bool = Field(description="ë²•ì  ê·¼ê±° ëª…ì‹œ ì—¬ë¶€")
    cites_retrieved_docs: bool = Field(description="ê²€ìƒ‰ ë¬¸ì„œ ì¸ìš© ì—¬ë¶€")
    is_relevant: bool = Field(description="ë‹µë³€ ì í•©ì„±")
    needs_more_search: bool = Field(description="ì¶”ê°€ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€")
    quality_score: int = Field(description="í’ˆì§ˆ ì ìˆ˜ (1-5)")
    improvement_suggestion: str = Field(default="", description="ê°œì„  ì œì•ˆ")
```

### í•„ë“œë³„ í‰ê°€ ê¸°ì¤€

| í•„ë“œ                     | í‰ê°€ ê¸°ì¤€                        | True ì˜ˆì‹œ                       | False ì˜ˆì‹œ               |
| ------------------------ | -------------------------------- | ------------------------------- | ------------------------ |
| `has_legal_basis`        | ë²•ë ¹ëª…, ì¡°í•­ ë²ˆí˜¸ ëª…ì‹œ ì—¬ë¶€      | "ê·¼ë¡œê¸°ì¤€ë²• ì œ36ì¡°ì— ë”°ë¥´ë©´..." | "ì¼ë°˜ì ìœ¼ë¡œ í‡´ì§ê¸ˆì€..." |
| `cites_retrieved_docs`   | ê²€ìƒ‰ ë¬¸ì„œ ì¸ìš© `[1]`, `[2]` ì‚¬ìš© | "...14ì¼ ì´ë‚´ì…ë‹ˆë‹¤[1]."        | ì¸ìš© ì—†ì´ ë‹µë³€ë§Œ ì‘ì„±    |
| `is_relevant`            | ì§ˆë¬¸ì— ì§ì ‘ ë‹µí•˜ëŠ”ê°€             | í‡´ì§ê¸ˆ ì§ˆë¬¸ì— í‡´ì§ê¸ˆ ë‹µë³€       | í‡´ì§ê¸ˆ ì§ˆë¬¸ì— í•´ê³  ë‹µë³€  |
| `needs_more_search`      | ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡± ì—¬ë¶€              | ê´€ë ¨ ë¬¸ì„œ 0-1ê°œ                 | ê´€ë ¨ ë¬¸ì„œ 3ê°œ ì´ìƒ       |
| `quality_score`          | ì¢…í•© í’ˆì§ˆ (1-5ì )                | 5ì : ì™„ë²½í•œ ë‹µë³€                | 1ì : ë‹µë³€ ë¶ˆê°€           |
| `improvement_suggestion` | ê°œì„  ë°©í–¥ ì œì•ˆ                   | "íŒë¡€ ì¶”ê°€ í•„ìš”"                | "" (ë¹ˆ ë¬¸ìì—´)           |

### ì‹¤ì œ LLM í‰ê°€ ì˜ˆì‹œ

#### ì¢‹ì€ ë‹µë³€ (ì¬ê²€ìƒ‰ ë¶ˆí•„ìš”)

```json
{
  "has_legal_basis": true,
  "cites_retrieved_docs": true,
  "is_relevant": true,
  "needs_more_search": false,
  "quality_score": 5,
  "improvement_suggestion": ""
}
```

â†’ **ë¼ìš°íŒ…**: `quality_score >= 3` â†’ END (ë‹µë³€ ë°˜í™˜)

#### ë‚˜ìœ ë‹µë³€ (ì¬ê²€ìƒ‰ í•„ìš”)

```json
{
  "has_legal_basis": false,
  "cites_retrieved_docs": false,
  "is_relevant": true,
  "needs_more_search": true,
  "quality_score": 2,
  "improvement_suggestion": "ê²€ìƒ‰ëœ ë¬¸ì„œì— êµ¬ì²´ì ì¸ ë²•ì¡°ë¬¸ì´ ì—†ìŒ. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì¬ê²€ìƒ‰ í•„ìš”"
}
```

â†’ **ë¼ìš°íŒ…**: `quality_score <= 2 AND needs_more_search == true` â†’ Search ë…¸ë“œë¡œ ì¬ê²€ìƒ‰

---

## ì™œ Pydanticì„ ì‚¬ìš©í•˜ëŠ”ê°€?

### 1. LLM ì¶œë ¥ ê°•ì œ (Structured Output)

**Pydantic ì—†ì´ (ê¸°ì¡´ ë°©ì‹)**:
```python
# LLMì´ ììœ  í˜•ì‹ìœ¼ë¡œ ë‹µë³€
response = llm.invoke("ì§ˆë¬¸ì„ ë¶„ì„í•´ì¤˜")
# ì¶œë ¥: "ì´ ì§ˆë¬¸ì€ ë…¸ë™ë²• ë¶„ì•¼ì´ê³ , ë‚œì´ë„ëŠ” ì¤‘ê°„ì…ë‹ˆë‹¤..."

# ìˆ˜ë™ íŒŒì‹± í•„ìš” (ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥)
if "ë…¸ë™ë²•" in response:
    category = "ë…¸ë™ë²•"
```

**Pydantic ì‚¬ìš© (í˜„ì¬ ë°©ì‹)**:
```python
# LLMì—ê²Œ JSON í˜•ì‹ ê°•ì œ
structured_llm = llm.with_structured_output(QueryAnalysis)
analysis = structured_llm.invoke("ì§ˆë¬¸ì„ ë¶„ì„í•´ì¤˜")

# ìë™ìœ¼ë¡œ QueryAnalysis ê°ì²´ë¡œ ë³€í™˜ë¨
print(analysis.category)  # "ë…¸ë™ë²•"
print(analysis.query_complexity)  # "medium"
```

### 2. íƒ€ì… ê²€ì¦ (Runtime Validation)

```python
# LLMì´ ì˜ëª»ëœ íƒ€ì… ë°˜í™˜ ì‹œ ìë™ ì˜¤ë¥˜ ê°ì§€
{
  "quality_score": "ë†’ìŒ"  # âŒ intê°€ ì•„ë‹Œ str
}
# Pydanticì´ ìë™ìœ¼ë¡œ ValidationError ë°œìƒ
```

### 3. ê¸°ë³¸ê°’ ì²˜ë¦¬

```python
# LLMì´ ì¼ë¶€ í•„ë“œë¥¼ ëˆ„ë½í•´ë„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ì›Œì§
QueryAnalysis(
    category="ë…¸ë™ë²•",
    intent_type="ë²•ë ¹ì¡°íšŒ"
    # needs_clarificationì€ ìë™ìœ¼ë¡œ False
    # query_complexityëŠ” ìë™ìœ¼ë¡œ "medium"
)
```

### 4. IDE ìë™ì™„ì„±

```python
analysis.  # â† IDEê°€ ìë™ìœ¼ë¡œ í•„ë“œ ëª©ë¡ í‘œì‹œ
# category, intent_type, needs_clarification, ...
```

---

## TypedDict vs Pydantic ë¹„êµ

| íŠ¹ì§•          | TypedDict (`AgentState`)         | Pydantic (`HybridQuery` ë“±)  |
| ------------- | -------------------------------- | ---------------------------- |
| **ìš©ë„**      | LangGraph ìƒíƒœ ê´€ë¦¬              | LLM ì¶œë ¥ êµ¬ì¡°í™”              |
| **íƒ€ì… ê²€ì¦** | âŒ ëŸ°íƒ€ì„ ê²€ì¦ ì—†ìŒ (íƒ€ì… íŒíŠ¸ë§Œ) | âœ… ëŸ°íƒ€ì„ ìë™ ê²€ì¦           |
| **ê¸°ë³¸ê°’**    | âŒ ì§€ì› ì•ˆ í•¨                     | âœ… `Field(default=...)`       |
| **LLM ì—°ë™**  | âŒ ë¶ˆê°€ëŠ¥                         | âœ… `with_structured_output()` |
| **ì„±ëŠ¥**      | âš¡ ë¹ ë¦„ (ê²€ì¦ ì—†ìŒ)               | ğŸ¢ ëŠë¦¼ (ê²€ì¦ ì˜¤ë²„í—¤ë“œ)       |
| **ì‚¬ìš© ì˜ˆ**   | ë…¸ë“œ ê°„ ë°ì´í„° ì „ë‹¬              | LLM ì‘ë‹µ íŒŒì‹±                |

---

## ìš”ì•½

`schemas.py`ëŠ” ì±—ë´‡ì˜ **ë°ì´í„° ê³„ì•½(Contract)**ì„ ì •ì˜í•˜ëŠ” í•µì‹¬ íŒŒì¼ì…ë‹ˆë‹¤:

1. **`AgentState`**: LangGraph ë…¸ë“œ ê°„ ìƒíƒœ ì „ë‹¬
2. **`HybridQuery`**: Query Expansion ê²°ê³¼ (Sparse + Dense + HyDE)
3. **`QueryAnalysis`**: ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼ (ë¼ìš°íŒ… ê²°ì •ì— ì‚¬ìš©)
4. **`AnswerEvaluation`**: ë‹µë³€ í’ˆì§ˆ í‰ê°€ (ì¬ê²€ìƒ‰ ì—¬ë¶€ ê²°ì •)

Pydanticì„ ì‚¬ìš©í•˜ì—¬ LLMì˜ ììœ ë¡œìš´ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ **êµ¬ì¡°í™”ëœ ë°ì´í„°**ë¡œ ê°•ì œí•˜ê³ , íƒ€ì… ì•ˆì •ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

---
### 2.5 `infrastructure.py`

**ì—­í• **: **ì™¸ë¶€ ë¦¬ì†ŒìŠ¤ ì—°ê²°** (Qdrant, ì„ë² ë”©, Reranker)

#### í´ë˜ìŠ¤ êµ¬ì¡°

```
infrastructure.py
â”œâ”€â”€ JinaReranker          (L20-L91)
â”œâ”€â”€ VectorStoreManager    (L97-L155)
â””â”€â”€ SparseEmbeddingManager (L158-L207)
```

---

#### 1) `JinaReranker`

```python
class JinaReranker(BaseDocumentCompressor):
    def __init__(self, model_name, top_n):
        # Device ìë™ ì„ íƒ: CUDA > MPS > CPU
        self.device = "cuda" if torch.cuda.is_available() else "mps" if ...
        
        # FP16 ì–‘ìí™”
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device != "cpu" else torch.float32
        )
    
    def compress_documents(self, documents, query):
        # [ì§ˆë¬¸, ë¬¸ì„œ] ìŒìœ¼ë¡œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        pairs = [[query, doc.page_content] for doc in documents]
        scores = self.model(**inputs).logits
        # ìƒìœ„ top_nê°œ ì„ íƒ
        return sorted_docs[:self.top_n]
```

**ìµœì í™” í¬ì¸íŠ¸**:
- **FP16 ì–‘ìí™”** (L53): GPU ë©”ëª¨ë¦¬ 50% ì ˆì•½
- **ë°°ì¹˜ ì²˜ë¦¬**: ëª¨ë“  ë¬¸ì„œë¥¼ í•œ ë²ˆì— ì²˜ë¦¬

---

#### 2) `VectorStoreManager`

```python
class VectorStoreManager:
    def initialize(self):
        # ì„ë² ë”© ëª¨ë¸ë§Œ ë¡œë”© (ë¬´ê±°ìš´ ì‘ì—…)
        self.embeddings = HuggingFaceEmbeddings(
            model_name=self.config.EMBEDDING_MODEL,
            encode_kwargs={'normalize_embeddings': True}
        )
    
    async def create_client(self) -> AsyncQdrantClient:
        # ë§¤ ìš”ì²­ë§ˆë‹¤ ìƒˆ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (Lazy Loading)
        return AsyncQdrantClient(
            url=self.qdrant_url,
            timeout=self.config.QDRANT_TIMEOUT,
            prefer_grpc=True  # gRPC ì‚¬ìš©
        )
```

**ì„¤ê³„ í¬ì¸íŠ¸**:
- **Lazy Loading**: Qdrant í´ë¼ì´ì–¸íŠ¸ëŠ” í•„ìš”í•  ë•Œë§Œ ìƒì„±
- **ì´ë²¤íŠ¸ ë£¨í”„ ì•ˆì „**: ì´ˆê¸°í™” ì‹œì ì— Async í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì•ˆ í•¨
- **ì—°ê²° ê´€ë¦¬**: ê²€ìƒ‰ í›„ `client.close()`ë¡œ ëª…ì‹œì  í•´ì œ

---

#### 3) `SparseEmbeddingManager`

```python
class SparseEmbeddingManager:
    def initialize(self):
        # BGE-M3 ëª¨ë¸ ë¡œë”©
        self.model = BGEM3FlagModel(
            self.config.SPARSE_EMBEDDING_MODEL,
            use_fp16=torch.cuda.is_available()
        )
    
    def encode_query(self, query: str) -> models.SparseVector:
        # Sparse ë²¡í„° ìƒì„± (í‚¤ì›Œë“œ ë§¤ì¹­ìš©)
        output = self.model.encode(
            query,
            return_sparse=True,
            return_dense=False
        )
        weights = output['lexical_weights']  # {token_id: weight}
        return models.SparseVector(indices=..., values=...)
```

**ì—­í• **: ë²•ë¥  ìš©ì–´ì˜ ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ìœ„í•œ í¬ì†Œ ë²¡í„° ìƒì„±

---
### 2.6 `graph.py`

**ì—­í• **: **LangGraph ë…¸ë“œ ë° ì›Œí¬í”Œë¡œìš° êµ¬ì„±**

#### í´ë˜ìŠ¤: `LegalRAGBuilder`

```python
class LegalRAGBuilder:
    def __init__(self, config: Config):
        self.config = config
        self.llm = None
        self.vs_manager = None
        self.reranker = None
    
    def set_components(self, vs_manager, reranker):
        # ë¯¸ë¦¬ ë¡œë”©ëœ ì»´í¬ë„ŒíŠ¸ ì£¼ì… (ì˜ì¡´ì„± ì£¼ì…)
        self.vs_manager = vs_manager
        self.reranker = reranker
    
    def build(self) -> CompiledStateGraph:
        # ê·¸ë˜í”„ ë¹Œë“œ
        builder = StateGraph(AgentState)
        builder.add_node("analyze", self._create_analyze_node())
        builder.add_node("search", self._create_search_node())
        ...
        return builder.compile()
```

#### ë…¸ë“œ ìƒì„± ë©”ì„œë“œ

| ë©”ì„œë“œ | ë…¸ë“œëª… | ì£¼ìš” ë¡œì§ |
|--------|--------|----------|
| `_create_analyze_node()` | analyze | LLMìœ¼ë¡œ ì§ˆë¬¸ ë¶„ì„ â†’ `QueryAnalysis` ë°˜í™˜ |
| `_create_clarify_node()` | clarify | ëª…í™•í™” ìš”ì²­ ë©”ì‹œì§€ ìƒì„± |
| `_create_search_node()` | search | **í•µì‹¬**: Hybrid Search + Reranking |
| `_create_generate_node()` | generate | ê²€ìƒ‰ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„± |
| `_create_evaluate_node()` | evaluate | ë‹µë³€ í’ˆì§ˆ í‰ê°€ |

---

#### í•µì‹¬ ë…¸ë“œ: `_create_search_node()` (L185-L296)

```python
async def search_documents(state: AgentState) -> dict:
    # 0. Qdrant í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = await self.vs_manager.create_client()
    
    try:
        # 1. Query Expansion (HyDE)
        hybrid = await query_expander(original_query)
        keyword_query = hybrid.keyword_query
        vector_query = hybrid.hyde_passage
        
        # 2. ì„ë² ë”© ìƒì„± (ë³‘ë ¬)
        dense_vec, sparse_vec = await asyncio.gather(
            asyncio.to_thread(embeddings.embed_query, vector_query),
            asyncio.to_thread(sparse_manager.encode_query, keyword_query)
        )
        
        # 3. Qdrant Hybrid Search
        vector_docs = await self._execute_search(
            client, dense_vec, sparse_vec, collection_name, limit=10
        )
        
        # 4. Reranking
        reranked_docs = await asyncio.to_thread(
            reranker.compress_documents, vector_docs, original_query
        )
        
        # 5. Filtering & Boosting
        final_docs = [doc for doc in reranked_docs 
                      if doc.metadata['relevance_score'] >= 0.2][:3]
    
    finally:
        await client.close()
    
    return {"retrieved_docs": final_docs}
```

**ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸**:
- **ë³‘ë ¬ ì„ë² ë”©** (L229): Dense/Sparse ë™ì‹œ ìƒì„±
- **ë¹„ë™ê¸° ê²€ìƒ‰** (L232): I/O ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”
- **ì—°ê²° í•´ì œ** (L250): ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€

---

#### ë¼ìš°íŒ… ë¡œì§

```python
def _route_after_analysis(state) -> Literal["clarify", "search"]:
    if state["query_analysis"]["needs_clarification"]:
        return "clarify"
    return "search"

def _route_after_generate(state) -> Literal["evaluate", "end"]:
    complexity = state["query_analysis"]["query_complexity"]
    if complexity == "simple":
        return "end"  # í‰ê°€ ìƒëµ
    return "evaluate"

def _route_after_evaluation(state) -> Literal["search", "end"]:
    if state["retry_count"] >= MAX_RETRY:
        return "end"
    if state["evaluation_result"]["quality_score"] <= 2:
        return "search"  # ì¬ê²€ìƒ‰
    return "end"
```

**ì¡°ê±´ë¶€ ì‹¤í–‰**ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ë…¸ë“œ ì‹¤í–‰ ë°©ì§€ â†’ ì„±ëŠ¥ í–¥ìƒ

---
## 3. íŒŒì¼ ê°„ ê´€ê³„ë„

### ì˜ì¡´ì„± ê·¸ë˜í”„

```
config.py (ì„¤ì •)
    â†“
prompts.py (í”„ë¡¬í”„íŠ¸)
    â†“
schemas.py (ë°ì´í„° êµ¬ì¡°)
    â†“
infrastructure.py (ì¸í”„ë¼)
    â†“ (Config, Schemas ì‚¬ìš©)
graph.py (ë¡œì§)
    â†“ (ëª¨ë“  ëª¨ë“ˆ ì‚¬ìš©)
__init__.py (ì§„ì…ì )
```

### ì„í¬íŠ¸ ê´€ê³„

| íŒŒì¼ | ì„í¬íŠ¸í•˜ëŠ” ëª¨ë“ˆ |
|------|------------------|
| `config.py` | `django.conf.settings`, `os` |
| `prompts.py` | (ì—†ìŒ - ìˆœìˆ˜ ë¬¸ìì—´) |
| `schemas.py` | `pydantic`, `langchain_core` |
| `infrastructure.py` | `config`, `torch`, `langchain_*` |
| `graph.py` | `config`, `schemas`, `infrastructure`, `prompts` |
| `__init__.py` | `config`, `infrastructure`, `graph` |

### ë°ì´í„° íë¦„

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
[graph.py] LegalRAGBuilder.build()
    â†“
[graph.py] analyze_node
    â†’ [prompts.py] PROMPT_ANALYZE
    â†’ [schemas.py] QueryAnalysis
    â†“
[graph.py] search_node
    â†’ [infrastructure.py] VectorStoreManager
    â†’ [infrastructure.py] SparseEmbeddingManager
    â†’ [infrastructure.py] JinaReranker
    â†“
[graph.py] generate_node
    â†’ [prompts.py] PROMPT_GENERATE
    â†“
ìµœì¢… ë‹µë³€
```

---
## 4. ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆ

### í˜„ì¬ ë³‘ëª© ì§€ì  ë¶„ì„

| ë‹¨ê³„ | ì†Œìš” ì‹œê°„ (ì˜ˆìƒ) | ë³‘ëª© ì›ì¸ |
|------|------------------|----------|
| **1. Analyze** | ~1ì´ˆ | LLM API í˜¸ì¶œ |
| **2. Query Expansion** | ~1ì´ˆ | LLM API í˜¸ì¶œ |
| **3. ì„ë² ë”© ìƒì„±** | ~0.5ì´ˆ | ëª¨ë¸ ì¶”ë¡  (CPU/GPU) |
| **4. Qdrant ê²€ìƒ‰** | ~0.3ì´ˆ | ë„¤íŠ¸ì›Œí¬ I/O |
| **5. Reranking** | ~0.5ì´ˆ | ëª¨ë¸ ì¶”ë¡  |
| **6. Generate** | ~2ì´ˆ | LLM API í˜¸ì¶œ (ê¸´ í”„ë¡¬í”„íŠ¸) |
| **7. Evaluate** | ~1ì´ˆ | LLM API í˜¸ì¶œ |
| **ì´í•©** | **~6.3ì´ˆ** | |

---

### ìµœì í™” ì „ëµ

#### ğŸš€ ì „ëµ 1: LLM í˜¸ì¶œ ìµœì†Œí™”

**í˜„ì¬ ë¬¸ì œ**: ì´ 4ë²ˆì˜ LLM í˜¸ì¶œ (Analyze, Expand, Generate, Evaluate)

**í•´ê²°ì±…**:

1. **Simple ì§ˆë¬¸ Fast Path**
   - Analyzeì—ì„œ `complexity == "simple"` íŒë‹¨ ì‹œ Expand, Evaluate ìƒëµ
   - **ì ˆê°**: ~2ì´ˆ

2. **Query Expansion ìºì‹±**
   - ë™ì¼ ì§ˆë¬¸ íŒ¨í„´ì€ ìºì‹œì—ì„œ ì¬ì‚¬ìš©
   - **ì ˆê°**: ~1ì´ˆ (ì¬ë°©ë¬¸ ì‹œ)

3. **Evaluate ì¡°ê±´ë¶€ ì‹¤í–‰** (ì´ë¯¸ êµ¬í˜„ë¨)
   - Simple ì§ˆë¬¸ì€ í‰ê°€ ìƒëµ

---

#### âš¡ ì „ëµ 2: ë³‘ë ¬ ì²˜ë¦¬ ê°•í™”

**í˜„ì¬ ë¬¸ì œ**: ì¼ë¶€ ë‹¨ê³„ê°€ ìˆœì°¨ ì‹¤í–‰

**í•´ê²°ì±…**:

1. **Analyze + Query Expansion ë³‘ë ¬í™”**
   ```python
   analysis, hybrid = await asyncio.gather(
       analyze_chain.ainvoke(query),
       expand_chain.ainvoke(query)
   )
   ```
   - **ì ˆê°**: ~1ì´ˆ

2. **ì„ë² ë”© ë³‘ë ¬í™”** (ì´ë¯¸ êµ¬í˜„ë¨)
   - Dense/Sparse ë™ì‹œ ìƒì„±

---

#### ğŸ”§ ì „ëµ 3: ëª¨ë¸ ìµœì í™”

**í˜„ì¬ ë¬¸ì œ**: ì„ë² ë”©/Reranking ëª¨ë¸ì´ ë¬´ê±°ì›€

**í•´ê²°ì±…**:

1. **ì„ë² ë”© ëª¨ë¸ ê²½ëŸ‰í™”**
   - `Qwen3-Embedding-0.6B` â†’ `all-MiniLM-L6-v2` (ë” ì‘ìŒ)
   - **ì ˆê°**: ~0.2ì´ˆ

2. **Reranker ì–‘ìí™”** (ì´ë¯¸ FP16 ì ìš©ë¨)
   - INT8 ì–‘ìí™” ì¶”ê°€ ê³ ë ¤

3. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**
   - Rerankerì˜ `max_length=512` â†’ `256`
   - **ì ˆê°**: ~0.1ì´ˆ

---

#### ğŸ—„ï¸ ì „ëµ 4: ê²€ìƒ‰ ìµœì í™”

**í˜„ì¬ ë¬¸ì œ**: ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ê°€ ë§ìŒ

**í•´ê²°ì±…**:

1. **TOP_K ê°’ ì¡°ì •**
   - `TOP_K_VECTOR: 10 â†’ 7`
   - `TOP_K_RERANK: 5 â†’ 3`
   - **ì ˆê°**: ~0.2ì´ˆ

2. **Qdrant íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•**
   - `QDRANT_TIMEOUT: 10 â†’ 5`
   - **íš¨ê³¼**: ì‹¤íŒ¨ ì‹œ ë¹ ë¥¸ í´ë°±

3. **gRPC ì‚¬ìš©** (ì´ë¯¸ ì ìš©ë¨)
   - `QDRANT_PREFER_GRPC: True`

---

#### ğŸ’¾ ì „ëµ 5: ìºì‹± ë„ì…

**í•´ê²°ì±…**:

1. **ì„ë² ë”© ìºì‹œ**
   ```python
   from functools import lru_cache
   
   @lru_cache(maxsize=100)
   def get_embedding(text: str):
       return embeddings.embed_query(text)
   ```
   - **ì ˆê°**: ~0.5ì´ˆ (ì¬ë°©ë¬¸ ì‹œ)

2. **ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ**
   - Redisì— ì§ˆë¬¸-ë¬¸ì„œ ë§¤í•‘ ì €ì¥
   - **ì ˆê°**: ~1ì´ˆ (ì¬ë°©ë¬¸ ì‹œ)

---

### ìµœì í™” íš¨ê³¼ ìš”ì•½

| ì „ëµ | ì˜ˆìƒ ì ˆê° ì‹œê°„ | ë‚œì´ë„ |
|------|----------------|--------|
| Simple Fast Path | ~2ì´ˆ | ì‰¬ì›€ |
| Analyze + Expand ë³‘ë ¬í™” | ~1ì´ˆ | ì¤‘ê°„ |
| TOP_K ê°’ ì¡°ì • | ~0.2ì´ˆ | ì‰¬ì›€ |
| ì„ë² ë”© ìºì‹± | ~0.5ì´ˆ (ì¬ë°©ë¬¸) | ì¤‘ê°„ |
| ê²€ìƒ‰ ê²°ê³¼ ìºì‹± | ~1ì´ˆ (ì¬ë°©ë¬¸) | ì–´ë ¤ì›€ |
| **ì´ ì ˆê°** | **~4.7ì´ˆ** | |
| **ìµœì¢… ì‘ë‹µ ì‹œê°„** | **~1.6ì´ˆ** | |

---
## 5. ìµœì í™” ì½”ë“œ ìˆ˜ì • ê°€ì´ë“œ

### ğŸ¯ ìµœì í™” 1: Simple Fast Path (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)

**ìˆ˜ì • íŒŒì¼**: `graph.py`

**ìˆ˜ì • ìœ„ì¹˜**: `_create_search_node()` ë©”ì„œë“œ ë‚´ë¶€ (L207-L219)

**Before**:
```python
# 1. Query Expansion (Async)
if query_expander:
    hybrid = await query_expander(original_query)
    keyword_query = hybrid.keyword_query
    vector_query = hybrid.hyde_passage
```

**After**:
```python
# 1. Query Expansion (ì¡°ê±´ë¶€)
complexity = analysis.get("query_complexity", "medium")

if complexity == "simple":
    # Simple ì§ˆë¬¸ì€ Query Expansion ìƒëµ
    keyword_query = original_query
    vector_query = original_query
    logger.info("Simple query - skipping query expansion")
elif query_expander:
    hybrid = await query_expander(original_query)
    keyword_query = hybrid.keyword_query
    vector_query = hybrid.hyde_passage
```

**íš¨ê³¼**: Simple ì§ˆë¬¸ ì‹œ ~1ì´ˆ ì ˆê°

**ì´ìœ **: 
- Simple ì§ˆë¬¸(ì˜ˆ: "ê·¼ë¡œê¸°ì¤€ë²• ì œ2ì¡°ê°€ ë­ì•¼?")ì€ ì´ë¯¸ ëª…í™•í•˜ë¯€ë¡œ Query Expansion ë¶ˆí•„ìš”
- LLM API í˜¸ì¶œ 1íšŒ ì ˆì•½

---

### ğŸ¯ ìµœì í™” 2: TOP_K ê°’ ì¡°ì •

**ìˆ˜ì • íŒŒì¼**: `config.py`

**ìˆ˜ì • ìœ„ì¹˜**: L22-L24

**Before**:
```python
TOP_K_VECTOR: int = getattr(settings, "TOP_K_VECTOR", 10)
TOP_K_RERANK: int = getattr(settings, "TOP_K_RERANK", 5)
TOP_K_FINAL: int = getattr(settings, "TOP_K_FINAL", 3)
```

**After**:
```python
TOP_K_VECTOR: int = getattr(settings, "TOP_K_VECTOR", 7)  # 10 â†’ 7
TOP_K_RERANK: int = getattr(settings, "TOP_K_RERANK", 3)  # 5 â†’ 3
TOP_K_FINAL: int = getattr(settings, "TOP_K_FINAL", 3)  # ìœ ì§€
```

**íš¨ê³¼**: ~0.2ì´ˆ ì ˆê°

**ì´ìœ **:
- ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ 10ê°œ â†’ 7ê°œ: Qdrant ê²€ìƒ‰ ì‹œê°„ ë‹¨ì¶•
- Reranker ì²˜ë¦¬ ë¬¸ì„œ 5ê°œ â†’ 3ê°œ: Reranker ì¶”ë¡  ì‹œê°„ ë‹¨ì¶•
- ìµœì¢… ë¬¸ì„œëŠ” 3ê°œë¡œ ìœ ì§€í•˜ì—¬ ë‹µë³€ í’ˆì§ˆ ë³´ì¥

---

### ğŸ¯ ìµœì í™” 3: Analyze + Expand ë³‘ë ¬í™”

**ìˆ˜ì • íŒŒì¼**: `graph.py`

**ìˆ˜ì • ìœ„ì¹˜**: ìƒˆë¡œìš´ ë…¸ë“œ ìƒì„± (L146 ì´í›„)

**Before** (í˜„ì¬ êµ¬ì¡°):
```
analyze â†’ search (ë‚´ë¶€ì—ì„œ expand í˜¸ì¶œ)
```

**After** (ë³‘ë ¬ êµ¬ì¡°):
```python
def _create_parallel_analyze_expand_node(self):
    """Analyzeì™€ Query Expansionì„ ë³‘ë ¬ ì‹¤í–‰"""
    analyze_llm = self.llm.with_structured_output(QueryAnalysis)
    expand_llm = self.llm.with_structured_output(HybridQuery)
    
    async def parallel_node(state: AgentState) -> dict:
        query = state["user_query"]
        
        # ë³‘ë ¬ ì‹¤í–‰
        analysis, hybrid = await asyncio.gather(
            analyze_llm.ainvoke({"query": query}),
            expand_llm.ainvoke({"query": query})
        )
        
        return {
            "query_analysis": analysis.model_dump(),
            "expanded_query": hybrid.model_dump()
        }
    
    return parallel_node
```

**ê·¸ë˜í”„ ìˆ˜ì •**:
```python
# build() ë©”ì„œë“œ ë‚´ë¶€
builder.add_node("analyze_expand", self._create_parallel_analyze_expand_node())
builder.set_entry_point("analyze_expand")
```

**íš¨ê³¼**: ~1ì´ˆ ì ˆê°

**ì´ìœ **:
- ë‘ LLM í˜¸ì¶œì´ ë™ì‹œì— ì‹¤í–‰ë¨
- ë„¤íŠ¸ì›Œí¬ I/O ëŒ€ê¸° ì‹œê°„ ì¤‘ë³µ ì œê±°

---

### ğŸ¯ ìµœì í™” 4: ì„ë² ë”© ìºì‹±

**ìˆ˜ì • íŒŒì¼**: `infrastructure.py`

**ìˆ˜ì • ìœ„ì¹˜**: `VectorStoreManager` í´ë˜ìŠ¤ (L97-L155)

**ì¶”ê°€ ì½”ë“œ**:
```python
from functools import lru_cache

class VectorStoreManager:
    def __init__(self, config: Config):
        # ... ê¸°ì¡´ ì½”ë“œ ...
        self._embedding_cache = {}  # ìºì‹œ ë”•ì…”ë„ˆë¦¬
    
    def get_embeddings(self) -> HuggingFaceEmbeddings:
        # ... ê¸°ì¡´ ì½”ë“œ ...
        
        # ìºì‹± ë˜í¼ ì¶”ê°€
        original_embed = self.embeddings.embed_query
        
        def cached_embed(text: str):
            if text in self._embedding_cache:
                logger.info("Embedding cache hit")
                return self._embedding_cache[text]
            
            result = original_embed(text)
            self._embedding_cache[text] = result
            return result
        
        self.embeddings.embed_query = cached_embed
        return self.embeddings
```

**íš¨ê³¼**: ~0.5ì´ˆ ì ˆê° (ë™ì¼ ì§ˆë¬¸ ì¬ë°©ë¬¸ ì‹œ)

**ì´ìœ **:
- ë™ì¼í•œ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ì¬ì‚¬ìš©
- ëª¨ë¸ ì¶”ë¡  ì‹œê°„ ì™„ì „ ì œê±°

---

### ğŸ¯ ìµœì í™” 5: Reranker ë°°ì¹˜ í¬ê¸° ì¡°ì •

**ìˆ˜ì • íŒŒì¼**: `infrastructure.py`

**ìˆ˜ì • ìœ„ì¹˜**: `JinaReranker.compress_documents()` (L68-L70)

**Before**:
```python
inputs = self.tokenizer(
    pairs, padding=True, truncation=True,
    return_tensors="pt", max_length=512
)
```

**After**:
```python
inputs = self.tokenizer(
    pairs, padding=True, truncation=True,
    return_tensors="pt", max_length=256  # 512 â†’ 256
)
```

**íš¨ê³¼**: ~0.1ì´ˆ ì ˆê°

**ì´ìœ **:
- í† í° ê¸¸ì´ ë‹¨ì¶•ìœ¼ë¡œ Transformer ì—°ì‚°ëŸ‰ ê°ì†Œ
- ë²•ë¥  ë¬¸ì„œëŠ” ë³´í†µ 256 í† í° ì´ë‚´ë¡œ í•µì‹¬ ë‚´ìš© í¬í•¨

---

### ğŸ“Š ìµœì í™” ì ìš© ìš°ì„ ìˆœìœ„

| ìˆœìœ„ | ìµœì í™” | ë‚œì´ë„ | íš¨ê³¼ | ì¶”ì²œë„ |
|------|--------|--------|------|--------|
| 1 | TOP_K ê°’ ì¡°ì • | â­ | 0.2ì´ˆ | â­â­â­â­â­ |
| 2 | Simple Fast Path | â­â­ | 1ì´ˆ | â­â­â­â­â­ |
| 3 | Reranker ë°°ì¹˜ í¬ê¸° | â­ | 0.1ì´ˆ | â­â­â­â­ |
| 4 | ì„ë² ë”© ìºì‹± | â­â­â­ | 0.5ì´ˆ | â­â­â­â­ |
| 5 | Analyze + Expand ë³‘ë ¬í™” | â­â­â­â­ | 1ì´ˆ | â­â­â­ |

**ê¶Œì¥ ì ìš© ìˆœì„œ**: 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5

---
## ğŸ“ ê²°ë¡ 

### ëª¨ë“ˆí™”ì˜ ì¥ì 

1. **ìœ ì§€ë³´ìˆ˜ì„±**: ê° íŒŒì¼ì´ ëª…í™•í•œ ì—­í• ì„ ê°€ì§
2. **í™•ì¥ì„±**: ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ í•´ë‹¹ ëª¨ë“ˆë§Œ ìˆ˜ì •
3. **í…ŒìŠ¤íŠ¸ ìš©ì´ì„±**: ê° ëª¨ë“ˆì„ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
4. **ì¬ì‚¬ìš©ì„±**: ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œë„ í™œìš© ê°€ëŠ¥

### ì„±ëŠ¥ ìµœì í™” ìš”ì•½

- **í˜„ì¬ ì‘ë‹µ ì‹œê°„**: ~6.3ì´ˆ
- **ìµœì í™” í›„**: ~1.6ì´ˆ (ì•½ 75% ê°œì„ )
- **í•µì‹¬ ì „ëµ**: LLM í˜¸ì¶œ ìµœì†Œí™”, ë³‘ë ¬ ì²˜ë¦¬, ìºì‹±

### ë‹¤ìŒ ë‹¨ê³„

1. **ëª¨ë‹ˆí„°ë§**: LangSmithë¡œ ê° ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
2. **A/B í…ŒìŠ¤íŠ¸**: ìµœì í™” ì „í›„ ë‹µë³€ í’ˆì§ˆ ë¹„êµ
3. **í”„ë¡œë•ì…˜ ë°°í¬**: ì ì§„ì ìœ¼ë¡œ ìµœì í™” ì ìš©

---

**ì‘ì„± ì™„ë£Œ**: 2026-01-29  
**ì´ íŒŒì¼ ìˆ˜**: 6ê°œ  
**ì´ ì½”ë“œ ë¼ì¸**: 905ì¤„ (ê¸°ì¡´ 965ì¤„ì—ì„œ ë¦¬íŒ©í† ë§)
